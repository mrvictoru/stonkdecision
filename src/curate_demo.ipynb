{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this notebook demonstrate how to cuate dataset with the utitlity function provided\n",
    "# it involved two steps, first we create or train appropriate agent, second is to sample those agents interaction with the environment and store them in a dataset\n",
    "\n",
    "# Let's get the stock ticker we would use for curating the dataset\n",
    "\n",
    "# this library is to get the list of tickers from NASDAQ and DOWJONES\n",
    "from gettickers import *\n",
    "nasdaq_tic = get_nasdaq_tickers()\n",
    "dow_tic = get_dow_tickers()\n",
    "\n",
    "# merge the lists and remove duplicates\n",
    "all_tickers = nasdaq_tic + dow_tic\n",
    "all_tickers = list(set(all_tickers))\n",
    "\n",
    "# let's get the first 10 tickers and check the number of tickers in the lists\n",
    "print(all_tickers[:10])\n",
    "print(len(nasdaq_tic))\n",
    "print(len(dow_tic))\n",
    "print(len(all_tickers))\n",
    "\n",
    "# agents can be created from RL (stable-baselines3)\n",
    "# set date range for stock data to train RL-agents\n",
    "\n",
    "# this will set  the parameter for the training of the agents\n",
    "start_date = \"2017-01-01\"\n",
    "num_days = 400\n",
    "interval = \"1d\"\n",
    "indicators = [\"Volume\", \"volume_cmf\", \"trend_macd\", \"momentum_rsi\", \"momentum_stoch_rsi\", \"trend_sma_fast\"]\n",
    "exlucde = [\"positive\", \"negative\", \"neutral\"]\n",
    "init_balance = 20000\n",
    "agent_output_path = \"trained_stable_agents/\"\n",
    "stable_training_json_path = \"training_stable_agents_config/\"\n",
    "normalize_params = {}\n",
    "\n",
    "# save these parameter as json config file using the utility function from getsttickers\n",
    "#create_json_files(all_tickers, start_date, num_days, interval, indicators, init_balance, agent_output_path, stable_training_json_path, normalize_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to train our agents with a normalize environment, therefore we need to calculate the mean and std of the stock trading data\n",
    "# we can do this by sampling other agents and storing their interaction with the environment in a dataset\n",
    "# then we can use the dataset to calculate the mean and std of the stock trading data\n",
    "\n",
    "# use the helper function to sample\n",
    "from curatedataset import non_stable_curate_run\n",
    "import os\n",
    "\n",
    "# open the path with the json config file and loop through each json file\n",
    "for json_file in os.listdir(stable_training_json_path):\n",
    "    if json_file.endswith(\".json\"):\n",
    "        json_path = os.path.join(stable_training_json_path, json_file)\n",
    "              \n",
    "        non_stable_curate_run(json_path, num_episodes=5, trade_range = [0.05, 0.7])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read one of the json file\n",
    "import os\n",
    "import json\n",
    "json_file_path = os.listdir(stable_training_json_path)[0]\n",
    "with open(os.path.join(stable_training_json_path, json_file_path), \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "print(config)\n",
    "\n",
    "# extract the configuration parameters\n",
    "stock_name = config['stock_name']\n",
    "start_date = config['start_date']\n",
    "num_days = config['num_days']\n",
    "interval = config['interval']\n",
    "indicators = config['indicators']\n",
    "init_balance = config['init_balance']\n",
    "output_path = config['output_path']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use the curated datasets to calculate the mean and std of the stock trading data using helper function\n",
    "from curatedataset import calc_meanstd_datasets\n",
    "dataset_mean_std = calc_meanstd_datasets(output_path,['positive', 'negative', 'neutral'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are utility functions in curatedataset to help make gymnasium environment from the stock data\n",
    "from curatedataset import makegymenv\n",
    "stable_env, obs_space, act_space, col, data = makegymenv(\n",
    "    stock_name=stock_name, start_date=start_date, period=num_days, interval=interval, \n",
    "    indicators=indicators, normalize=dataset_mean_std, init_balance=init_balance)\n",
    "\n",
    "# Stable-baselines3 library can be used to create and train the agents\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from train_stable_agent import evaluate_stable_agent\n",
    "\n",
    "num_cpu = 6\n",
    "# vectorized environment\n",
    "env_vec = SubprocVecEnv([lambda: stable_env for i in range(num_cpu)])\n",
    "# create the agent\n",
    "modelA2C = A2C(\"MlpPolicy\", env_vec, verbose=1)\n",
    "# we can evaluate the agent before training\n",
    "mean_reward, std_reward = evaluate_stable_agent(modelA2C, Monitor(stable_env), n_eval_ep=10, deterministic=False)\n",
    "print(f\"Pre-training -> mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")\n",
    "\n",
    "# train the agent\n",
    "modelA2C.learn(total_timesteps=len(data)*80)\n",
    "\n",
    "# evaluate the agent after training\n",
    "mean_reward, std_reward = evaluate_stable_agent(modelA2C, Monitor(stable_env), n_eval_ep=10, deterministic=False)\n",
    "print(f\"Post training -> mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the steps above can be used to train multiple agents and store them in a folder with the utility function in get_agent.py\n",
    "from train_stable_agent import full_run\n",
    "\n",
    "json_files = os.listdir(stable_training_json_path)\n",
    "\n",
    "# loop through all json file and train stable-baseline agent with utility function\n",
    "for file in json_files:\n",
    "    # check if file ends with json\n",
    "    if file.endswith(\".json\"):\n",
    "        runfile = os.path.join(stable_training_json_path, file)\n",
    "        print(f\"Training agent with {runfile}\")\n",
    "        with open(runfile, \"r\") as f:\n",
    "            runconfig = json.load(f)\n",
    "        output_path = runconfig[\"output_path\"]\n",
    "        # check if the agent file has already been created\n",
    "        # create a list of files in the output path and end with .zip\n",
    "\n",
    "        if os.path.exists(output_path) and len([file for file in os.listdir(output_path) if file.endswith(\".zip\")]) == 3:\n",
    "            print(f\"Agent with {runfile} already trained\")\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                full_run(runfile)\n",
    "            except Exception as e:\n",
    "                print(f\"Error training agent with {runfile}\")\n",
    "                print(e)\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that stable-baseline agent is trained, we can go and sample them in the stock trading environment with different dates\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "# calculate the new start_date as the start_date + num_days for training stable-baseline agent\n",
    "start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "new_start_date = start_date + timedelta(days=num_days)\n",
    "\"\"\"\n",
    "# we want to sample the agents for the days different between start date and now (today) minus 120 days (those 120 days for testing)\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "today = datetime.strptime(today, \"%Y-%m-%d\")\n",
    "day_diff = (today - new_start_date).days\n",
    "\n",
    "\n",
    "if day_diff < 180:\n",
    "    num_days = day_diff\n",
    "else:\n",
    "    num_days = day_diff - 180\n",
    "\"\"\"\n",
    "num_days = 800\n",
    "\n",
    "new_start_date = new_start_date.strftime(\"%Y-%m-%d\")\n",
    "data_output_path = \"offline_stock_trade_data/\"\n",
    "data_json_path = \"offline_stock_trade_data_config/\"\n",
    "\n",
    "# save these parameter as json config file using the utility function from getsttickers\n",
    "#create_json_files(all_tickers, new_start_date, num_days, interval, indicators, init_balance, data_output_path, data_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read one of the json file\n",
    "json_file_path = os.listdir(data_json_path)[0]\n",
    "\n",
    "with open(os.path.join(data_json_path, json_file_path), \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "print(config)\n",
    "\n",
    "# extract the configuration parameters\n",
    "stock_name = config['stock_name']\n",
    "start_date = config['start_date']\n",
    "num_days = config['num_days']\n",
    "interval = config['interval']\n",
    "indicators = config['indicators']\n",
    "init_balance = config['init_balance']\n",
    "output_path = config['output_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import utility for running environment\n",
    "from curatedataset import makegymenv, run_env\n",
    "\n",
    "# make the gymnasium environment\n",
    "data_env, obs_space, act_space, col, data = makegymenv(\n",
    "    stock_name=stock_name, start_date=start_date, period=num_days, interval=interval, \n",
    "    indicators=indicators, normalize=False, init_balance=init_balance, random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Agent class\n",
    "from get_agent import Agent, TradingAlgorithm\n",
    "\n",
    "# here is how to run the environment with a random agent\n",
    "momentum_algo = 'momentum_stoch_rsi'\n",
    "# find the momentum_stoch_rsi column\n",
    "momentum_stoch_rsi_col = col.index(momentum_algo)\n",
    "momentum_trade_algo = TradingAlgorithm(algo_type = momentum_algo, indicator_column = momentum_stoch_rsi_col, amount_range = [0.05,0.4])\n",
    "# by default agent has safeguard set to true, it prevent agent from buying if the budget is not enough to buy any more shares\n",
    "momentum_algo_agent = Agent(data_env, 'algo', algo = momentum_trade_algo)\n",
    "# get the list of date from the data\n",
    "env_date = data.index.strftime(\"%Y-%m-%d\").tolist()\n",
    "\n",
    "trade_data = run_env(momentum_algo_agent, stock_name, data_env, num_episodes=3, date=env_date, normalize_param=False, deterministic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will first sample non-stable agents and store their interaction with the environment in a dataset\n",
    "# this can be used to calculate the mean and std of the stock trading data for stable agents\n",
    "from curatedataset import non_stable_curate_run\n",
    "import os\n",
    "\n",
    "# open the path with the json config file and loop through each json file\n",
    "for json_file in os.listdir(data_json_path):\n",
    "    if json_file.endswith(\".json\"):\n",
    "        json_path = os.path.join(data_json_path, json_file)\n",
    "        print(f\"Curating data with {json_path}\")\n",
    "        # run the environment with random start date within the period\n",
    "        with open(json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        # get the ticker\n",
    "        ticker = data['stock_name']\n",
    "        output = data[\"output_path\"]\n",
    "        # check if the output path exists and if it contain data, if so skip\n",
    "        if os.path.exists(output) and len(os.listdir(output)) == 4:\n",
    "            print(f\"Data already curated for {ticker} from non-stable agents\")\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                non_stable_curate_run(json_path, random = True)\n",
    "            except Exception as e:\n",
    "                print(f\"Error curating data with {json_path} from non-stable agents\")\n",
    "                print(e)\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use the curated datasets to calculate the mean and std of the stock trading data using helper function like previously\n",
    "from curatedataset import calc_meanstd_datasets, makegymenv, run_env\n",
    "dataset_mean_std = calc_meanstd_datasets(output_path,['positive', 'negative', 'neutral'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from get_agent import Agent\n",
    "# make the gymnasium environment\n",
    "data_env, obs_space, act_space, col, data = makegymenv(\n",
    "    stock_name=stock_name, start_date=start_date, period=num_days, interval=interval, \n",
    "    indicators=indicators, normalize=dataset_mean_std, init_balance=init_balance, random=True)\n",
    "# here is how to run the environment with the trained stable-baseline agent\n",
    "# get the list of date from the data\n",
    "env_date = data.index.strftime(\"%Y-%m-%d\").tolist()\n",
    "# get the folder where the trained agents are stored\n",
    "agent_folder = os.path.join(agent_output_path, stock_name)\n",
    "# get the a2c agent path\n",
    "for file in os.listdir(agent_folder):\n",
    "    if file.endswith(\".zip\") and \"a2c\" in file:\n",
    "        a2c_agent_path = os.path.join(os.getcwd(),agent_folder, file)\n",
    "        break\n",
    "a2c_agent = Agent(data_env, \"stable-baselines-a2c\", model_path = a2c_agent_path)\n",
    "# run the environment with the agent\n",
    "trade_data = run_env(a2c_agent, stock_name, data_env, num_episodes=5, date=env_date, normalize_param=dataset_mean_std, deterministic=False)\n",
    "\n",
    "# inspect the data keys\n",
    "print(data.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the aboved step can be done with utility function from curatedataset.py\n",
    "from curatedataset import stable_curate_run\n",
    "\n",
    "data_json_files = os.listdir(data_json_path)\n",
    "\n",
    "# loop through all json file and run environment with trained stable agent and other algorithms\n",
    "for file in data_json_files:\n",
    "    # check if file ends with json\n",
    "    if file.endswith(\".json\"):\n",
    "        runfile = os.path.join(data_json_path, file)\n",
    "        print(f\"Curating data with {runfile}\")\n",
    "        # open the json file and read the content\n",
    "        with open(runfile, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        # get the ticker\n",
    "        ticker = data['stock_name']\n",
    "        output = data[\"output_path\"]\n",
    "        # check if the output path exists and if it contain data, if so skip\n",
    "        if os.path.exists(output) and len(os.listdir(output)) == 7:\n",
    "            print(f\"Data already curated for {ticker} from stable agents\")\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                # joining the output path with ticker\n",
    "                trained_stable_agent_path = os.path.join(agent_output_path, ticker)\n",
    "                stable_curate_run(runfile, trained_stable_agent_path, num_episodes=80)\n",
    "            except Exception as e:\n",
    "                print(f\"Error curating data with {runfile} from stable agents\")\n",
    "                print(e)\n",
    "                continue\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
